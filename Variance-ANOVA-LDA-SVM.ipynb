{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f783e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b03d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gene_ex = pd.read_csv(\"data-TCGA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "549d220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene = pd.DataFrame(data_gene_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ec4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = pd.read_csv(\"labels-TCGA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd64c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.DataFrame(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e54caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db838948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label['Class'].replace({'BRCA':0, 'KIRC':1, \"LUAD\":2, \"PRAD\":3, \"COAD\":4}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a13549ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene1 = df_gene.copy()\n",
    "df_gene1 = df_gene1.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79e2340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene2 = df_gene1.copy()\n",
    "df_gene2 = df_gene2.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e768edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_gene2\n",
    "y = df_label.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "570fec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47c7847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "x_scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70df0e9",
   "metadata": {},
   "source": [
    "# Removing Low Variance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ee1910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance for each gene\n",
    "gene_variances_sorted = x_train.var(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f848d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after keeping top 2000 genes: (640, 2000)\n",
      "Shape after keeping top 2000 genes: (161, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Keep top N genes\n",
    "N = 2000\n",
    "top_genes = gene_variances_sorted.index[:N]\n",
    "x_train_top_var = x_train[top_genes]\n",
    "x_test_top_var = x_test[top_genes]\n",
    "\n",
    "x_new = x.copy()\n",
    "x_new = x_new[top_genes]\n",
    "\n",
    "print(f\"Shape after keeping top {N} genes:\", x_train_top_var.shape)\n",
    "print(f\"Shape after keeping top {N} genes:\", x_test_top_var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ad918",
   "metadata": {},
   "source": [
    "# ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c72fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVIDEH\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "selector = SelectKBest(f_classif, k=1000)\n",
    "x_train_sel = selector.fit_transform(x_train_top_var, y_train)\n",
    "x_test_sel = selector.transform(x_test_top_var)\n",
    "x_sel = selector.transform(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83fe7264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_9176</th>\n",
       "      <th>gene_9175</th>\n",
       "      <th>gene_15898</th>\n",
       "      <th>gene_15301</th>\n",
       "      <th>gene_15589</th>\n",
       "      <th>gene_3540</th>\n",
       "      <th>gene_19661</th>\n",
       "      <th>gene_3541</th>\n",
       "      <th>gene_11250</th>\n",
       "      <th>gene_15897</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_10106</th>\n",
       "      <th>gene_11772</th>\n",
       "      <th>gene_7998</th>\n",
       "      <th>gene_9564</th>\n",
       "      <th>gene_7474</th>\n",
       "      <th>gene_13152</th>\n",
       "      <th>gene_1059</th>\n",
       "      <th>gene_2572</th>\n",
       "      <th>gene_8906</th>\n",
       "      <th>gene_16450</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.557821</td>\n",
       "      <td>12.295416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.315229</td>\n",
       "      <td>1.966947</td>\n",
       "      <td>17.607518</td>\n",
       "      <td>8.492262</td>\n",
       "      <td>13.902987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.648354</td>\n",
       "      <td>14.415082</td>\n",
       "      <td>10.780622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.769018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.919464</td>\n",
       "      <td>5.759787</td>\n",
       "      <td>5.397361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0.404576</td>\n",
       "      <td>2.380868</td>\n",
       "      <td>0.404576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.367524</td>\n",
       "      <td>3.132495</td>\n",
       "      <td>10.971436</td>\n",
       "      <td>4.696395</td>\n",
       "      <td>1.556993</td>\n",
       "      <td>2.288299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.902378</td>\n",
       "      <td>8.544149</td>\n",
       "      <td>8.955086</td>\n",
       "      <td>5.461267</td>\n",
       "      <td>3.546351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.078234</td>\n",
       "      <td>7.512693</td>\n",
       "      <td>3.585780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.078815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.807117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.118225</td>\n",
       "      <td>13.151083</td>\n",
       "      <td>15.131552</td>\n",
       "      <td>5.958358</td>\n",
       "      <td>12.240374</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078815</td>\n",
       "      <td>4.903086</td>\n",
       "      <td>14.716557</td>\n",
       "      <td>10.019188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.468231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.022723</td>\n",
       "      <td>7.492558</td>\n",
       "      <td>3.599734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.896194</td>\n",
       "      <td>11.665056</td>\n",
       "      <td>2.345822</td>\n",
       "      <td>1.708673</td>\n",
       "      <td>9.608575</td>\n",
       "      <td>0.931607</td>\n",
       "      <td>1.708673</td>\n",
       "      <td>1.493084</td>\n",
       "      <td>...</td>\n",
       "      <td>4.672476</td>\n",
       "      <td>5.590569</td>\n",
       "      <td>6.694058</td>\n",
       "      <td>10.503826</td>\n",
       "      <td>1.896194</td>\n",
       "      <td>8.072165</td>\n",
       "      <td>5.053728</td>\n",
       "      <td>5.272725</td>\n",
       "      <td>10.921424</td>\n",
       "      <td>3.869042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.385859</td>\n",
       "      <td>6.346090</td>\n",
       "      <td>14.759191</td>\n",
       "      <td>8.046229</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>6.246967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.367004</td>\n",
       "      <td>6.618115</td>\n",
       "      <td>13.558074</td>\n",
       "      <td>7.441749</td>\n",
       "      <td>7.312892</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>2.823138</td>\n",
       "      <td>6.390542</td>\n",
       "      <td>3.476161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>18.166516</td>\n",
       "      <td>16.418269</td>\n",
       "      <td>2.577175</td>\n",
       "      <td>13.105047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.620104</td>\n",
       "      <td>3.687374</td>\n",
       "      <td>6.120070</td>\n",
       "      <td>14.213750</td>\n",
       "      <td>6.810919</td>\n",
       "      <td>...</td>\n",
       "      <td>4.313050</td>\n",
       "      <td>4.035615</td>\n",
       "      <td>8.630922</td>\n",
       "      <td>12.041012</td>\n",
       "      <td>4.545641</td>\n",
       "      <td>4.745888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.745587</td>\n",
       "      <td>6.962618</td>\n",
       "      <td>4.990946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.924100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.697640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.754655</td>\n",
       "      <td>12.142551</td>\n",
       "      <td>13.938348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.032048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.981068</td>\n",
       "      <td>6.337611</td>\n",
       "      <td>3.556993</td>\n",
       "      <td>0.534759</td>\n",
       "      <td>0.924100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.430641</td>\n",
       "      <td>2.864394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.221452</td>\n",
       "      <td>12.067323</td>\n",
       "      <td>11.769387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.385276</td>\n",
       "      <td>2.868924</td>\n",
       "      <td>15.945064</td>\n",
       "      <td>7.742242</td>\n",
       "      <td>8.588658</td>\n",
       "      <td>...</td>\n",
       "      <td>1.176961</td>\n",
       "      <td>8.071301</td>\n",
       "      <td>10.746430</td>\n",
       "      <td>10.322998</td>\n",
       "      <td>1.176961</td>\n",
       "      <td>6.996999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.754928</td>\n",
       "      <td>7.989480</td>\n",
       "      <td>5.255520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2.396954</td>\n",
       "      <td>1.351402</td>\n",
       "      <td>1.113500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.158630</td>\n",
       "      <td>5.461286</td>\n",
       "      <td>12.752947</td>\n",
       "      <td>5.716728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.555571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472904</td>\n",
       "      <td>7.452579</td>\n",
       "      <td>7.430043</td>\n",
       "      <td>10.538975</td>\n",
       "      <td>4.668885</td>\n",
       "      <td>6.489101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.594653</td>\n",
       "      <td>6.678565</td>\n",
       "      <td>3.310573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1.310049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.341378</td>\n",
       "      <td>11.662904</td>\n",
       "      <td>15.932212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.154486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.096536</td>\n",
       "      <td>9.561347</td>\n",
       "      <td>4.595647</td>\n",
       "      <td>3.374344</td>\n",
       "      <td>1.571725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.793188</td>\n",
       "      <td>8.672033</td>\n",
       "      <td>4.338645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_9176  gene_9175  gene_15898  gene_15301  gene_15589  gene_3540  \\\n",
       "697   0.000000   0.000000   19.557821   12.295416    0.000000  10.315229   \n",
       "668   0.404576   2.380868    0.404576    0.000000   15.367524   3.132495   \n",
       "63    1.078815   0.000000   19.807117    0.000000    0.000000   7.118225   \n",
       "534   0.000000   0.000000    1.896194   11.665056    2.345822   1.708673   \n",
       "66    0.000000   0.000000    0.744333    0.000000    3.385859   6.346090   \n",
       "..         ...        ...         ...         ...         ...        ...   \n",
       "799  18.166516  16.418269    2.577175   13.105047    0.000000   6.620104   \n",
       "745   0.924100   0.000000    1.697640    0.000000    0.000000  15.754655   \n",
       "513   0.000000   4.221452   12.067323   11.769387    0.000000  15.385276   \n",
       "671   2.396954   1.351402    1.113500    0.000000   13.158630   5.461286   \n",
       "264   1.310049   0.000000    0.578407    0.000000    0.000000  16.341378   \n",
       "\n",
       "     gene_19661  gene_3541  gene_11250  gene_15897  ...  gene_10106  \\\n",
       "697    1.966947  17.607518    8.492262   13.902987  ...    0.000000   \n",
       "668   10.971436   4.696395    1.556993    2.288299  ...    0.000000   \n",
       "63    13.151083  15.131552    5.958358   12.240374  ...    1.078815   \n",
       "534    9.608575   0.931607    1.708673    1.493084  ...    4.672476   \n",
       "66    14.759191   8.046229    0.744333    6.246967  ...    0.000000   \n",
       "..          ...        ...         ...         ...  ...         ...   \n",
       "799    3.687374   6.120070   14.213750    6.810919  ...    4.313050   \n",
       "745   12.142551  13.938348    0.000000    3.032048  ...    0.000000   \n",
       "513    2.868924  15.945064    7.742242    8.588658  ...    1.176961   \n",
       "671   12.752947   5.716728    0.000000    1.555571  ...    0.472904   \n",
       "264   11.662904  15.932212    0.000000    2.154486  ...    0.000000   \n",
       "\n",
       "     gene_11772  gene_7998  gene_9564  gene_7474  gene_13152  gene_1059  \\\n",
       "697    8.648354  14.415082  10.780622   0.000000    6.769018   0.000000   \n",
       "668    8.902378   8.544149   8.955086   5.461267    3.546351   0.000000   \n",
       "63     4.903086  14.716557  10.019188   0.000000    4.468231   0.000000   \n",
       "534    5.590569   6.694058  10.503826   1.896194    8.072165   5.053728   \n",
       "66     7.367004   6.618115  13.558074   7.441749    7.312892   0.744333   \n",
       "..          ...        ...        ...        ...         ...        ...   \n",
       "799    4.035615   8.630922  12.041012   4.545641    4.745888   0.000000   \n",
       "745    9.981068   6.337611   3.556993   0.534759    0.924100   0.000000   \n",
       "513    8.071301  10.746430  10.322998   1.176961    6.996999   0.000000   \n",
       "671    7.452579   7.430043  10.538975   4.668885    6.489101   0.000000   \n",
       "264    8.096536   9.561347   4.595647   3.374344    1.571725   0.000000   \n",
       "\n",
       "     gene_2572  gene_8906  gene_16450  \n",
       "697   3.919464   5.759787    5.397361  \n",
       "668   3.078234   7.512693    3.585780  \n",
       "63    7.022723   7.492558    3.599734  \n",
       "534   5.272725  10.921424    3.869042  \n",
       "66    2.823138   6.390542    3.476161  \n",
       "..         ...        ...         ...  \n",
       "799   7.745587   6.962618    4.990946  \n",
       "745   0.000000  10.430641    2.864394  \n",
       "513   7.754928   7.989480    5.255520  \n",
       "671   5.594653   6.678565    3.310573  \n",
       "264   1.793188   8.672033    4.338645  \n",
       "\n",
       "[161 rows x 1000 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the selected feature names\n",
    "selected_feature_names = x_train_top_var.columns[selector.get_support()]\n",
    "\n",
    "# Create DataFrames with selected features and their actual values\n",
    "x_train_selected_df = pd.DataFrame(x_train_sel, columns=selected_feature_names)\n",
    "x_test_selected_df = pd.DataFrame(x_test_sel, columns=selected_feature_names, index=x_test.index)\n",
    "x_selected_df = pd.DataFrame(x_sel, columns=selected_feature_names, index=x.index)\n",
    "\n",
    "x_test_selected_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb62d1e",
   "metadata": {},
   "source": [
    "# LDA as dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f358081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVIDEH\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=min(len(np.unique(y_train)) - 1, 10))\n",
    "x_train_final = lda.fit_transform(x_train_selected_df, y_train)\n",
    "x_test_final = lda.transform(x_test_selected_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0bd2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm model with different kernels and degree = 3 and gamma= 0.7\n",
    "\n",
    "\n",
    "def svm(x_tr, x_te):\n",
    "    \n",
    "    for k in ['linear', 'rbf', 'poly']:\n",
    "        \n",
    "        svm_model = SVC(kernel=k, degree=3, gamma=0.7)\n",
    "        start = time.time()\n",
    "        svm_model.fit(x_tr, y_train.ravel())\n",
    "        train_time = time.time() - start\n",
    "\n",
    "        y_svm_pred = svm_model.predict(x_te)\n",
    "        acc = accuracy_score(y_test, y_svm_pred)\n",
    "\n",
    "        \n",
    "        print(f\"{k}, accuracy = {acc:.4f}, training_time = {train_time:.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79f7fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear, accuracy = 1.0000, training_time = 0.4000 sec\n",
      "rbf, accuracy = 0.4099, training_time = 0.0650 sec\n",
      "poly, accuracy = 0.9876, training_time = 0.0000 sec\n"
     ]
    }
   ],
   "source": [
    "svm(x_train_final,x_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ae45534",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model1 = SVC(kernel='poly', degree=3, gamma=0.7)\n",
    "\n",
    "svm_model1.fit(x_train_final, y_train.ravel())\n",
    "\n",
    "y_svm_pred1 = svm_model1.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f169178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        61\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       1.00      0.97      0.98        29\n",
      "           3       1.00      0.97      0.98        29\n",
      "           4       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report of svm with kernel = ploy and degree=3 and gamma=0.7\n",
    "print(classification_report(y_test, svm_model1.predict(x_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0de21948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        61\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       1.00      0.97      0.98        29\n",
      "           3       1.00      0.97      0.98        29\n",
      "           4       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.99       161\n",
      "   macro avg       0.99      0.99      0.99       161\n",
      "weighted avg       0.99      0.99      0.99       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report of svm with kernel = linear and degree=3 and gamma=0.7\n",
    "\n",
    "svm_model2 = SVC(kernel='poly', degree=3, gamma=0.7)\n",
    "\n",
    "svm_model2.fit(x_train_final, y_train.ravel())\n",
    "\n",
    "y_svm_pred2 = svm_model2.predict(x_test_final)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, svm_model2.predict(x_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc9f1466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.31      0.47        61\n",
      "           1       1.00      0.40      0.57        25\n",
      "           2       1.00      0.17      0.29        29\n",
      "           3       0.23      1.00      0.38        29\n",
      "           4       1.00      0.18      0.30        17\n",
      "\n",
      "    accuracy                           0.41       161\n",
      "   macro avg       0.85      0.41      0.40       161\n",
      "weighted avg       0.86      0.41      0.42       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report of svm with kernel = linear and degree=3 and gamma=0.7\n",
    "\n",
    "svm_model3 = SVC(kernel='rbf', degree=3, gamma=0.7)\n",
    "\n",
    "svm_model3.fit(x_train_final, y_train.ravel())\n",
    "\n",
    "y_svm_pred3 = svm_model3.predict(x_test_final)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, svm_model3.predict(x_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc98ac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear, accuracy = 1.0000, training_time = 0.0051 sec\n",
      "rbf, accuracy = 1.0000, training_time = 0.0000 sec\n",
      "poly, accuracy = 0.9814, training_time = 0.0000 sec\n"
     ]
    }
   ],
   "source": [
    "def svm (x_tr, x_te):\n",
    "\n",
    "      for k in ['linear', 'rbf', 'poly']:\n",
    "\n",
    "        svm_model = SVC(kernel= k)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        svm_model.fit(x_tr, y_train.ravel())\n",
    "        train_time = time.time() - start\n",
    "\n",
    "        y_svm_pred = svm_model.predict(x_te)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_svm_pred)\n",
    "\n",
    "        \n",
    "        print(f\"{k}, accuracy = {acc:.4f}, training_time = {train_time:.4f} sec\")\n",
    "\n",
    "        \n",
    "\n",
    "svm(x_train_final,x_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53143c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        61\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       1.00      1.00      1.00        29\n",
      "           3       1.00      1.00      1.00        29\n",
      "           4       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report of svm with kernel = linear \n",
    "\n",
    "svm_model4 = SVC(kernel='linear')\n",
    "\n",
    "svm_model4.fit(x_train_final, y_train.ravel())\n",
    "\n",
    "y_svm_pred4 = svm_model4.predict(x_test_final)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, svm_model4.predict(x_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae9a0058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        61\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       1.00      1.00      1.00        29\n",
      "           3       1.00      1.00      1.00        29\n",
      "           4       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00       161\n",
      "   macro avg       1.00      1.00      1.00       161\n",
      "weighted avg       1.00      1.00      1.00       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report of svm with kernel = rbf\n",
    "\n",
    "svm_model5 = SVC(kernel='rbf')\n",
    "\n",
    "svm_model5.fit(x_train_final, y_train.ravel())\n",
    "\n",
    "y_svm_pred5 = svm_model5.predict(x_test_final)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, svm_model5.predict(x_test_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f966bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        61\n",
      "           1       1.00      1.00      1.00        25\n",
      "           2       1.00      0.93      0.96        29\n",
      "           3       1.00      0.97      0.98        29\n",
      "           4       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.99      0.98      0.98       161\n",
      "weighted avg       0.98      0.98      0.98       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report of svm with kernel = poly \n",
    "\n",
    "svm_model6 = SVC(kernel='poly')\n",
    "\n",
    "svm_model6.fit(x_train_final, y_train.ravel())\n",
    "\n",
    "y_svm_pred6 = svm_model6.predict(x_test_final)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, svm_model6.predict(x_test_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce5cd2d",
   "metadata": {},
   "source": [
    "We can see that the models performance with LDA is poorer than without it. So, LDA in some models has negative effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
